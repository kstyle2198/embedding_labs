{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use **BGE-M3** (a **dense retrieval model**) and extract the **normalized hidden state of the special token \\[CLS\\]** as the dense embedding, follow these steps:\n",
    "\n",
    "### **1. Install Dependencies**\n",
    "Ensure you have `transformers` and `torch` installed:\n",
    "\n",
    "```bash\n",
    "pip install transformers torch\n",
    "```\n",
    "\n",
    "### **2. Load the BGE-M3 Model**\n",
    "Use Hugging Face's `AutoModel` and `AutoTokenizer`:\n",
    "\n",
    "```python\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"BAAI/bge-m3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "```\n",
    "\n",
    "### **3. Tokenize Input**\n",
    "Tokenize the text while ensuring that `[CLS]` is included:\n",
    "\n",
    "```python\n",
    "text = \"This is an example sentence.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "```\n",
    "\n",
    "### **4. Get Hidden States**\n",
    "Pass the tokenized input through the model:\n",
    "\n",
    "```python\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Extract last hidden state\n",
    "hidden_states = outputs.last_hidden_state  # Shape: (batch_size, seq_length, hidden_dim)\n",
    "```\n",
    "\n",
    "### **5. Extract `[CLS]` Token Embedding**\n",
    "The `[CLS]` token is the first token in BERT-based models:\n",
    "\n",
    "```python\n",
    "cls_embedding = hidden_states[:, 0, :]  # Shape: (batch_size, hidden_dim)\n",
    "```\n",
    "\n",
    "### **6. Normalize the Embedding**\n",
    "Normalize the extracted `[CLS]` embedding using L2 normalization:\n",
    "\n",
    "```python\n",
    "cls_embedding = torch.nn.functional.normalize(cls_embedding, p=2, dim=1)\n",
    "```\n",
    "\n",
    "### **7. Convert to Numpy (Optional)**\n",
    "If needed, convert the embedding to a NumPy array:\n",
    "\n",
    "```python\n",
    "cls_embedding_np = cls_embedding.cpu().numpy()\n",
    "```\n",
    "\n",
    "### **Summary of Key Points**\n",
    "- Tokenize text with `[CLS]` included.\n",
    "- Extract the **first token's hidden state** from `outputs.last_hidden_state`.\n",
    "- **L2 normalize** the `[CLS]` embedding for consistency.\n",
    "- Use the result as the **dense embedding** for retrieval tasks.\n",
    "\n",
    "This normalized `[CLS]` embedding is what BGE-M3 uses for efficient dense retrieval. ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaModel(\n",
       "  (embeddings): XLMRobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
       "    (position_embeddings): Embedding(8194, 1024, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): XLMRobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-23): 24 x XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSdpaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): XLMRobertaPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"D:/LLMs/bge-m3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[     0,     87,   1884,    142, 108787,      2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I like an apple\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.1833,  0.6057, -1.1345,  ...,  0.2107, -0.8259,  0.3222],\n",
       "         [-0.1086,  0.0092, -0.5508,  ...,  0.2070, -0.5216,  0.2273],\n",
       "         [ 0.5871, -0.0714, -0.7237,  ...,  0.4825, -0.4838,  0.5969],\n",
       "         [ 0.2916,  0.0894, -0.3398,  ...,  0.5961, -1.0075,  0.2712],\n",
       "         [ 0.5557, -0.2793, -0.2761,  ...,  0.2340, -0.3755, -0.2263],\n",
       "         [-0.2901,  0.4516, -0.3684,  ...,  0.8776, -0.8294,  0.6854]]]), pooler_output=tensor([[-0.8096,  0.4748,  0.0235,  ..., -0.2627,  0.1331, -0.1672]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "print(len(outputs[\"pooler_output\"][0]))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.1833,  0.6057, -1.1345,  ...,  0.2107, -0.8259,  0.3222],\n",
       "          [-0.1086,  0.0092, -0.5508,  ...,  0.2070, -0.5216,  0.2273],\n",
       "          [ 0.5871, -0.0714, -0.7237,  ...,  0.4825, -0.4838,  0.5969],\n",
       "          [ 0.2916,  0.0894, -0.3398,  ...,  0.5961, -1.0075,  0.2712],\n",
       "          [ 0.5557, -0.2793, -0.2761,  ...,  0.2340, -0.3755, -0.2263],\n",
       "          [-0.2901,  0.4516, -0.3684,  ...,  0.8776, -0.8294,  0.6854]]]),\n",
       " 6,\n",
       " 1024)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract last hidden state\n",
    "hidden_states = outputs.last_hidden_state  # Shape: (batch_size, seq_length, hidden_dim)\n",
    "hidden_states, len(hidden_states[0]), len(hidden_states[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1833,  0.6057, -1.1345,  ...,  0.2107, -0.8259,  0.3222]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_embedding = hidden_states[:, 0, :]  # Shape: (batch_size, hidden_dim)\n",
    "cls_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0069,  0.0229, -0.0430,  ...,  0.0080, -0.0313,  0.0122]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_embedding = torch.nn.functional.normalize(cls_embedding, p=2, dim=1)\n",
    "cls_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00694152,  0.02293514, -0.04296022, ...,  0.00797774,\n",
       "        -0.03127418,  0.0122012 ]], shape=(1, 1024), dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_embedding_np = cls_embedding.cpu().numpy()\n",
    "cls_embedding_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
